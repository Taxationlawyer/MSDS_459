# Part Four

This section covers the advent of ChatGPT, including Large Language Models (LLMs). LLMS process an incredible amount of information and learn patterns in the process of doing so. In order for a ChatGPT to be able to give an accurate answer, the model must have learned the issue and solution beforehand. ChatGPT memorizes patters through a process called reinforcement learning. LLMs employ heavy pattern recognition. Chatbots appear to be highly intelligent, but the tools merely produce a response based on learned patterns. LLMs lack the ability to reason like human beings. Against that backdrop, this piece covers three main ideas: 1. reinforcement learning, 2. lack of common-sense reasoning in LLMs, and 3. model complexity. 

(1)	LLMs “learn” by memorizing patterns and applying the learned issues (the patterns with answers) to inquiries. This means that LLMs are biased because the models produce answers that are based solely on what the models have been exposed to. For example, and LLM can answer a coding question only if the LLM has previously been fed the issue. The LLM cannot solve a “new,” (not previously memorized by the LLM), coding task. The solution requires the intelligence of a capable human being. This learning process is commonly referred to as generalization (learning patterns and applying the same knowledge—learned patterns, to inquiries). Another feature that aids LLMs in the learning process is reinforcement learning. For example, the chatbot might have a “like” or “helpful” response button; this tells the LLM if the response is good or not. 

(2)	From all of this, it follows that LLMs lack common sense reasoning. While the chatbot answers might appear to be highly intelligent to some people, the chatbot is merely regurgitating information from learned patterns. Some of the LLMs are trained on readily available information. For example, The BERT model comes pretrained on Wikipedia, 2.5 billion words, (yes, the encyclopedia that at one time was not considered a legitimate source of information is now at the forefront of artificial intelligence) and BookCorpus (a collection of books that amounts to around 800 million words) (Ozdemir 2023). The BERT model (a transformer method) is superior to other artificial intelligence algorithms—specifically other neural network methods, especially recurrent neural networks. Traditional neural networks are at a disadvantage because the neurons are connected in sequence and are bottlenecked therefor. Attention (or focus of the neurons) is performed one neuron at a time because the nodes are sequentially connected.

(3)	Consequently, an LLM has to process and digest an incredible amount of information. For that reason, running such models requires high computing power (graphical processing units, GPUs), time, and resources (including electricity). An LLM can have trillions of parameters; this requires resources (computational, human, electricity and other resources). Fortunately, there are pretrained models available (e.g., the BERTH Model).

In summary, while LLMs appear to be highly intelligent, the algorithms are merely regurgitating information learned from pattern recognition (generalization). It is refreshing to know that jobs and opportunities are still available to competent data scientists, because human intelligence has not been replaced by Artificial intelligence. 

**References**

* Lane, Hobson and Maria Dyshel. 2025. Natural Language Processing in Action (second edition). Shelter Island, NY: Manning. [ISBN-13: 978-1617299445] Chapter 10, Large language models in the real world, pages 410–469. Available on Course Reserves, and Chapter 11, Information extraction and knowledge graphs, pages 470–512. Available on Course Reserves.

* Ozdemir, Sinan. 2023. “Introduction to Transformer Models for NLP: Using BERT, GPT, and More to Solve Modern Natural Language Processing Tasks.” O’Reilly. 2023. https://learning.oreilly.com/course/introduction-to-transformer/9780137923717/.
